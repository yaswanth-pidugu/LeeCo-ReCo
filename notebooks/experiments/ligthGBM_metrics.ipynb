{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-07T04:21:23.354356Z",
     "start_time": "2025-11-07T04:21:13.726277Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "DATA_PATH = Path(r\"C:\\Users\\yashw\\PycharmProjects\\PythonProject4\\data\\processed\\preprocessed_data.csv\")\n",
    "EMB_PATH  = Path(r\"C:\\Users\\yashw\\PycharmProjects\\PythonProject4\\models\\sbert_recommender.pkl\")\n",
    "MODEL_PATH = Path(r\"C:\\Users\\yashw\\PycharmProjects\\PythonProject4\\models\\lambdarank_model.pkl\")\n",
    "\n",
    "with open(EMB_PATH, \"rb\") as f:\n",
    "    cache = pickle.load(f)\n",
    "embeddings = np.array(cache[\"embeddings\"], dtype=np.float32)\n",
    "\n",
    "with open(MODEL_PATH, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Basic cleaning for consistency\n",
    "import ast, re\n",
    "def clean_title(t):\n",
    "    t = str(t).lower().strip()\n",
    "    t = re.sub(r'^\\d+\\.\\s*', '', t)\n",
    "    t = re.sub(r'[^a-z0-9\\s\\-]', '', t)\n",
    "    t = re.sub(r'\\s+', ' ', t)\n",
    "    return t\n",
    "\n",
    "def parse_similar(x):\n",
    "    try:\n",
    "        if isinstance(x, str):\n",
    "            return [clean_title(i) for i in ast.literal_eval(x)]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df['clean_title'] = df['title'].apply(clean_title)\n",
    "df['ground_truth'] = df['similar_questions'].apply(parse_similar)\n",
    "df['difficulty'] = df['difficulty'].fillna('Medium')\n",
    "df['topic_tags'] = df['topic_tags'].fillna('').astype(str)\n",
    "\n",
    "# Difficulty & popularity setup\n",
    "ladder = {\"easy\":0,\"medium\":1,\"hard\":2}\n",
    "diff_vals = df['difficulty'].str.lower().map(ladder).fillna(1).to_numpy(dtype=np.int8)\n",
    "def minmax(x):\n",
    "    x = x.fillna(0)\n",
    "    rng = x.max() - x.min()\n",
    "    return (x - x.min()) / rng if rng != 0 else x * 0\n",
    "\n",
    "acc = minmax(df['acceptance'])\n",
    "likes = minmax(df['likes'])\n",
    "subs = minmax(df['submission'])\n",
    "popularity = (0.3*acc + 0.5*likes + 0.2*subs).fillna(0).to_numpy(dtype=np.float32)\n",
    "\n",
    "# Helper: tag list + Jaccard\n",
    "import ast\n",
    "def to_tag_list(s):\n",
    "    if isinstance(s, str) and s.startswith('['):\n",
    "        try:\n",
    "            vals = ast.literal_eval(s)\n",
    "            return [v.lower().strip() for v in vals]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return [t.strip().lower() for t in str(s).split(',') if t.strip()]\n",
    "\n",
    "df['tag_list'] = df['topic_tags'].apply(to_tag_list)\n",
    "tag_sets = [set(t) for t in df['tag_list']]\n",
    "\n",
    "def tag_sim(i, j):\n",
    "    a, b = tag_sets[i], tag_sets[j]\n",
    "    if not a or not b: return 0.0\n",
    "    return len(a & b) / len(a | b)\n",
    "\n",
    "def rec_lambdarank(i, k=10):\n",
    "    sims = embeddings @ embeddings[i]\n",
    "    diff_s = np.array([1.0 if abs(diff_vals[i]-diff_vals[j])==0 else 0.7 if abs(diff_vals[i]-diff_vals[j])==1 else 0.4 for j in range(len(df))])\n",
    "    pop_diffs = np.abs(popularity[i] - popularity)\n",
    "    tag_s = np.array([tag_sim(i, j) for j in range(len(df))])\n",
    "    feats = np.stack([sims, tag_s, diff_s, pop_diffs], axis=1)\n",
    "    preds = model.predict(feats)\n",
    "    preds[i] = -1e9\n",
    "    top_idx = np.argsort(preds)[-k:][::-1]\n",
    "    return [df.iloc[j]['clean_title'] for j in top_idx]\n",
    "\n",
    "def precision_recall_ndcg(k=10, limit=300):\n",
    "    P, R, N = [], [], []\n",
    "    for i in tqdm(range(min(limit, len(df)))):\n",
    "        gt = df.loc[i, 'ground_truth']\n",
    "        if not gt:\n",
    "            continue\n",
    "        preds = rec_lambdarank(i, k)\n",
    "        hits = len(set(preds) & set(gt))\n",
    "        p = hits / k\n",
    "        r = hits / len(gt)\n",
    "        rel = [1 if x in gt else 0 for x in preds[:k]]\n",
    "        dcg = sum(r_ / np.log2(idx+2) for idx, r_ in enumerate(rel))\n",
    "        idcg = sum(sorted(rel, reverse=True)[i]/np.log2(i+2) for i in range(len(rel)))\n",
    "        ndcg = dcg/idcg if idcg>0 else 0\n",
    "        P.append(p); R.append(r); N.append(ndcg)\n",
    "    return np.mean(P), np.mean(R), np.mean(N)\n",
    "\n",
    "print(\"\\nEvaluating LambdaRank on 300 random problems...\")\n",
    "P, R, N = precision_recall_ndcg(k=10, limit=300)\n",
    "print(f\"\\nLambdaRank → Precision@10={P:.4f}, Recall@10={R:.4f}, NDCG@10={N:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LambdaRank on 300 random problems...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:08<00:00, 34.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LambdaRank → Precision@10=0.1467, Recall@10=0.4581, NDCG@10=0.5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
